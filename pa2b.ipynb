{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:03:30.446235Z",
     "start_time": "2024-03-23T01:03:30.382373Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Loading datasets\n",
    "higher_ed_df = pd.read_csv('dataset/subset_higher_ed_ednum.csv')\n",
    "some_college_df = pd.read_csv('dataset/subset_some_college_ednum.csv')\n",
    "less_than_hs_df = pd.read_csv('dataset/subset_less_than_hs_ednum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(   Age  Workclass  EdNum  MaritalStatus  Occupation  Relationship  Race  Sex  \\\n 0   39          5     13              4           0             1     4    1   \n 1   50          4     13              2           3             0     4    1   \n 2   28          2     13              2           9             5     2    0   \n 3   37          2     14              2           3             5     4    0   \n 4   31          2     14              4           9             1     4    0   \n \n    CapitalGain  CapitalLoss  HoursPerWeek  Country  Income  \n 0         2174            0            40       37       0  \n 1            0            0            13       37       0  \n 2            0            0            40        4       0  \n 3            0            0            40       37       0  \n 4        14084            0            50       37       1  ,\n    Age  Workclass  EdNum  MaritalStatus  Occupation  Relationship  Race  Sex  \\\n 0   38          2      9              0           5             1     4    1   \n 1   52          4      9              2           3             0     4    1   \n 2   37          2     10              2           3             0     2    1   \n 3   32          2     12              4          11             1     2    1   \n 4   25          4      9              4           4             3     4    1   \n \n    CapitalGain  CapitalLoss  HoursPerWeek  Country  Income  \n 0            0            0            40       38       0  \n 1            0            0            45       38       1  \n 2            0            0            80       38       1  \n 3            0            0            50       38       0  \n 4            0            0            35       38       0  ,\n    Age  Workclass  EdNum  MaritalStatus  Occupation  Relationship  Race  Sex  \\\n 0   53          2      7              2           5             0     2    1   \n 1   49          2      5              3           7             1     2    0   \n 2   34          2      4              2          13             0     0    1   \n 3   38          2      7              2          11             0     4    1   \n 4   35          0      5              2           4             0     2    1   \n \n    CapitalGain  CapitalLoss  HoursPerWeek  Country  Income  \n 0            0            0            40       34       0  \n 1            0            0            16       19       0  \n 2            0            0            45       22       0  \n 3            0            0            50       34       0  \n 4            0            0            40       34       0  )"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Dropping 'fnlgwt' and 'Education' features from all datasets as they are not useful or duplicated\n",
    "higher_ed_df = higher_ed_df.drop(['fnlgwt', 'Education'], axis=1)\n",
    "some_college_df = some_college_df.drop(['fnlgwt', 'Education'], axis=1)\n",
    "less_than_hs_df = less_than_hs_df.drop(['fnlgwt', 'Education'], axis=1)\n",
    "\n",
    "# Encoding categorical features in all datasets\n",
    "def encode_features(df):\n",
    "    label_encoders = {}\n",
    "    for column in df.select_dtypes(include=['object']).columns:\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        df[column] = label_encoders[column].fit_transform(df[column])\n",
    "    return df, label_encoders\n",
    "\n",
    "higher_ed_df_encoded, higher_ed_encoders = encode_features(higher_ed_df.copy())\n",
    "some_college_df_encoded, some_college_encoders = encode_features(some_college_df.copy())\n",
    "less_than_hs_df_encoded, less_than_hs_encoders = encode_features(less_than_hs_df.copy())\n",
    "\n",
    "(higher_ed_df_encoded.head(), some_college_df_encoded.head(), less_than_hs_df_encoded.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:03:30.999635Z",
     "start_time": "2024-03-23T01:03:30.887883Z"
    }
   },
   "id": "e57ad61a7b79a576",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Defining the input features and target variable for each subset\n",
    "X_higher_ed = higher_ed_df_encoded.drop('Income', axis=1)\n",
    "y_higher_ed = higher_ed_df_encoded['Income']\n",
    "\n",
    "X_some_college = some_college_df_encoded.drop('Income', axis=1)\n",
    "y_some_college = some_college_df_encoded['Income']\n",
    "\n",
    "X_less_than_hs = less_than_hs_df_encoded.drop('Income', axis=1)\n",
    "y_less_than_hs = less_than_hs_df_encoded['Income']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:03:31.916901Z",
     "start_time": "2024-03-23T01:03:31.674758Z"
    }
   },
   "id": "97b0251766485c2b",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. K-Nearest Neighbors (KNN)\n",
    "\n",
    "Function Call:\n",
    "~~~python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "~~~\n",
    "Hyperparameter: n_neighbors\n",
    "\n",
    "Values for Testing: 1, 3, 5, 7, 9"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daac1f3ecd7f4b0f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setting up K values for tuning\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Function to perform KNN tuning and plotting\n",
    "def tune_knn(X, y, k_values, title):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    mean_cv_scores = []\n",
    "    for k in k_values:\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "        cv_scores = cross_val_score(knn_clf, X, y, cv=5)\n",
    "        mean_cv_scores.append(np.mean(cv_scores))\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_values, mean_cv_scores, marker='o')\n",
    "    plt.title(f'5-Fold CV Accuracy vs. K for {title}')\n",
    "    plt.xlabel('Number of Neighbors (k)')\n",
    "    plt.ylabel('CV Mean Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "tune_knn(X_higher_ed, y_higher_ed, k_values, \"Higher Education Subset\")\n",
    "tune_knn(X_higher_ed, y_higher_ed, k_values, \"Some College Subset\")\n",
    "tune_knn(X_higher_ed, y_higher_ed, k_values, \"Less than High School Subset\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba7d9110605ff69",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Artificial Neural Network (ANN)\n",
    "\n",
    "Function Call:\n",
    "~~~python\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "ann_clf = MLPClassifier(hidden_layer_sizes=(100,), activation='relu')\n",
    "~~~\n",
    "Hyperparameter: hidden_layer_sizes (for the number of neurons in the hidden layers)\n",
    "\n",
    "Values for Testing: [(50,), (100,), (100,50), (100,100), (50,50,50)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bc55c250e83bcf0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Configurations for the hidden layer sizes to test\n",
    "hidden_layer_sizes = [(50,), (100,), (100,50), (100,100), (50,50,50)]\n",
    "\n",
    "def tune_ann(X, y, hidden_layer_sizes, title):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    mean_cv_scores_ann = []\n",
    "    for size in hidden_layer_sizes:\n",
    "        print('Size of hidden layer: ', size)\n",
    "        ann_clf = MLPClassifier(hidden_layer_sizes=size, activation='relu', max_iter=1000)\n",
    "        cv_scores = cross_val_score(ann_clf, X, y, cv=5)\n",
    "        mean_cv_scores_ann.append(np.mean(cv_scores))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot([str(size) for size in hidden_layer_sizes], mean_cv_scores_ann, marker='o')\n",
    "    plt.title(f'5-Fold CV Accuracy vs. Hidden Layer Sizes for {title}')\n",
    "    plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "    plt.ylabel('CV Mean Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "tune_ann(X_higher_ed, y_higher_ed, hidden_layer_sizes, \"Higher Education Subset\")\n",
    "tune_ann(X_higher_ed, y_higher_ed, hidden_layer_sizes, \"Some College Subset\")\n",
    "tune_ann(X_higher_ed, y_higher_ed, hidden_layer_sizes, \"Less than High School Subset\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8ce6751e5febcfc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "class CustomANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(CustomANN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, hidden_layers[0]), nn.ReLU()]\n",
    "        \n",
    "        for i in range(len(hidden_layers) - 1):\n",
    "            layers.append(nn.Linear(hidden_layers[i], hidden_layers[i + 1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_layers[-1], output_size))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:03:37.767920Z",
     "start_time": "2024-03-23T01:03:36.772203Z"
    }
   },
   "id": "982ca02b3d88c83b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tune_ann_pytorch(X, y, hidden_layer_sizes, title, k_folds=5, epochs=100):\n",
    "    print(1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "    print(2)\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    \n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for size in hidden_layer_sizes:\n",
    "        fold_performance = []\n",
    "        \n",
    "        for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "            print(f'Fold {fold}, Hidden Layer Size: {size}')\n",
    "            \n",
    "            train_subsampler = Subset(dataset, train_ids)\n",
    "            test_subsampler = Subset(dataset, test_ids)\n",
    "            \n",
    "            train_loader = DataLoader(train_subsampler, batch_size=64, shuffle=True)\n",
    "            test_loader = DataLoader(test_subsampler, batch_size=64, shuffle=False)\n",
    "            \n",
    "            model = CustomANN(input_size=X.shape[1], hidden_layers=size, output_size=len(np.unique(y)))\n",
    "            model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "            \n",
    "            # Training loop\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                for data, target in train_loader:\n",
    "                    data, target = data.to('cuda'), target.to('cuda')\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            # Evaluation loop\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in test_loader:\n",
    "                    data, target = data.to('cuda'), target.to('cuda')\n",
    "                    output = model(data)\n",
    "                    pred = output.argmax(dim=1, keepdim=True)\n",
    "                    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            fold_performance.append(100. * correct / len(test_subsampler))\n",
    "        \n",
    "        results[size] = np.mean(fold_performance)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot([str(size) for size in hidden_layer_sizes], list(results.values()), marker='o')\n",
    "    plt.title(f'5-Fold CV Accuracy vs. Hidden Layer Sizes for {title}')\n",
    "    plt.xlabel('Number of Neurons in Hidden Layer(s)')\n",
    "    plt.ylabel('CV Mean Accuracy (%)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:04:25.774348Z",
     "start_time": "2024-03-23T01:04:25.768837Z"
    }
   },
   "id": "550f2b8620a6973f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hidden_layer_sizes = [(50,), (100,), (100,50), (100,100), (50,50,50)]\n",
    "\n",
    "# 调用函数评估“Higher Education Subset”\n",
    "tune_ann_pytorch(X_higher_ed, y_higher_ed, hidden_layer_sizes, \"Higher Education Subset\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-23T01:04:26.556371Z"
    }
   },
   "id": "f3cf679cdbbdac60"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Decision Tree\n",
    "\n",
    "Function Call:\n",
    "\n",
    "~~~python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(max_depth=5)\n",
    "~~~\n",
    "Hyperparameter: max_depth\n",
    "\n",
    "Values for Testing: 3, 5, 7, 9, None (no limit)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89dc89c2e83389ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    \n",
    "def tune_decision_tree_actual_depth(X, y, max_depth_values, title):\n",
    "    mean_cv_scores_dt = []\n",
    "    depths_for_plot = max_depth_values.copy()  # Copy the list to avoid modifying the original\n",
    "    \n",
    "    for depth in max_depth_values:\n",
    "        if depth is None:\n",
    "            # Fit the tree without depth restriction\n",
    "            dt_clf = DecisionTreeClassifier(max_depth=None)\n",
    "            dt_clf.fit(X, y)  # Fit the model to find out the actual depth\n",
    "            actual_depth = dt_clf.get_depth()  # Get the actual depth of the tree\n",
    "            depths_for_plot[-1] = actual_depth  # Replace None with actual depth for plotting\n",
    "        # else:\n",
    "        dt_clf = DecisionTreeClassifier(max_depth=depth)\n",
    "        \n",
    "        cv_scores = cross_val_score(dt_clf, X, y, cv=5)\n",
    "        mean_cv_scores_dt.append(np.mean(cv_scores))\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(depths_for_plot, mean_cv_scores_dt, marker='o')\n",
    "    plt.title(f'5-Fold CV Accuracy vs. Max Depth for {title} (Actual Depth for None)')\n",
    "    plt.xlabel('Max Depth')\n",
    "    plt.ylabel('CV Mean Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(depths_for_plot)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Define the list of max_depth values to test\n",
    "max_depth_values = [3, 5, 7, 9, None]\n",
    "\n",
    "tune_decision_tree_actual_depth(X_higher_ed, y_higher_ed, max_depth_values, \"Higher Education Subset\")\n",
    "tune_decision_tree_actual_depth(X_some_college, y_some_college, max_depth_values, \"Some College Subset\")\n",
    "tune_decision_tree_actual_depth(X_less_than_hs, y_less_than_hs, max_depth_values, \"Less than High School Subset\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "189a89c0188749f4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Random Forest\n",
    "\n",
    "Function Call:\n",
    "\n",
    "~~~python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "~~~\n",
    "Hyperparameter: n_estimators (number of trees)\n",
    "\n",
    "Values for Testing: 10, 50, 100, 150, 200"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31247444fe2cc8f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def tune_random_forest(X, y, n_estimators_values, title):\n",
    "    mean_cv_scores_rf = []\n",
    "    \n",
    "    for n_estimators in n_estimators_values:\n",
    "        rf_clf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "        cv_scores = cross_val_score(rf_clf, X, y, cv=5)\n",
    "        mean_cv_scores_rf.append(np.mean(cv_scores))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(n_estimators_values, mean_cv_scores_rf, marker='o')\n",
    "    plt.title(f'5-Fold CV Accuracy vs. Number of Trees for {title}')\n",
    "    plt.xlabel('Number of Trees (n_estimators)')\n",
    "    plt.ylabel('CV Mean Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "n_estimators_values = [10, 50, 100, 150, 200]\n",
    "\n",
    "tune_random_forest(X_higher_ed, y_higher_ed, n_estimators_values, \"Higher Education Subset\")\n",
    "tune_random_forest(X_some_college, y_some_college, n_estimators_values, \"Some College Subset\")\n",
    "tune_random_forest(X_less_than_hs, y_less_than_hs, n_estimators_values, \"Less than High School Subset\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d7d42b469b07b99",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Naïve Bayes Classifier\n",
    "\n",
    "Function Call:\n",
    "~~~python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf = GaussianNB(var_smoothing=1e-9)\n",
    "~~~\n",
    "Hyperparameter: var_smoothing (portion of the largest variance of all features added to variances for calculation stability)\n",
    "\n",
    "Values for Testing: 1e-9, 1e-8, 1e-7, 1e-6, 1e-5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6743aded564c0f8d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def tune_naive_bayes(X, y, var_smoothing_values, title):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    mean_cv_scores_nb = []\n",
    "    \n",
    "    for var_smoothing in var_smoothing_values:\n",
    "        nb_clf = GaussianNB(var_smoothing=var_smoothing)\n",
    "        cv_scores = cross_val_score(nb_clf, X, y, cv=5)\n",
    "        mean_cv_scores_nb.append(np.mean(cv_scores))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.semilogx(var_smoothing_values, mean_cv_scores_nb, marker='o', base=10)\n",
    "    plt.title(f'5-Fold CV Accuracy vs. Var Smoothing for {title}')\n",
    "    plt.xlabel('Var Smoothing')\n",
    "    plt.ylabel('CV Mean Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "var_smoothing_values = [1e-12, 1e-9, 1e-6, 1e-3, 1e-1]\n",
    "\n",
    "tune_naive_bayes(X_higher_ed, y_higher_ed, var_smoothing_values, \"Higher Education Subset\")\n",
    "tune_naive_bayes(X_some_college, y_some_college, var_smoothing_values, \"Some College Subset\")\n",
    "tune_naive_bayes(X_less_than_hs, y_less_than_hs, var_smoothing_values, \"Less than High School Subset\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dafd65645006beb4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Support Vector Machine (SVM)\n",
    "\n",
    "Function Call:\n",
    "~~~python\n",
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(kernel='rbf')\n",
    "~~~\n",
    "Hyperparameters: kernel\n",
    "\n",
    "Values for Testing: ['rbf', 'sigmoid', 'linear', 'poly']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cf76e21a083b9cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "\n",
    "def tune_svm(X, y, kernels, title):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    mean_cv_scores_svm = []\n",
    "\n",
    "    for kernel in kernels:\n",
    "        print(\"Processing:\", kernel)\n",
    "        if kernel == 'linear':\n",
    "            # 使用LinearSVC\n",
    "            svm_clf = LinearSVC()\n",
    "        else:\n",
    "            # 使用SVC的其他核\n",
    "            svm_clf = SVC(kernel=kernel)\n",
    "\n",
    "        cv_scores = cross_val_score(svm_clf, X, y, cv=5)\n",
    "        mean_cv_scores_svm.append(np.mean(cv_scores))\n",
    "\n",
    "    # 可视化结果\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(kernels, mean_cv_scores_svm)\n",
    "    plt.title(f'5-Fold CV Accuracy vs. Kernel for {title}')\n",
    "    plt.xlabel('Kernel')\n",
    "    plt.ylabel('CV Mean Accuracy')\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.show()\n",
    "\n",
    "kernels = ['rbf', 'sigmoid', 'linear', 'poly']\n",
    "\n",
    "tune_svm(X_higher_ed, y_higher_ed, kernels, \"Higher Education Subset\")\n",
    "tune_svm(X_some_college, y_some_college, kernels, \"Some College Subset\")\n",
    "tune_svm(X_less_than_hs, y_less_than_hs, kernels, \"Less than High School Subset\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cf9f58980bdffa5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "44e743b4f74baac1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
